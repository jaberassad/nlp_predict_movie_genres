{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d87d1b4b",
      "metadata": {
        "id": "d87d1b4b"
      },
      "source": [
        "Hi there!\n",
        "This is the code template for CW2 task2 of COMP34711 2025/26.\n",
        "\n",
        "- <span style=\"color:red; font-size:1em\">First of all, please rename the notebook into \"{your_student_id}_CW2_task{your_task_number}.ipynb\", for example \"12345678_CW2_task2.ipynb\".</span>\n",
        "\n",
        "- In this template, we only provide the minimal structure for your coursework.\n",
        "  \n",
        "- Please carefully read and organize your code in the template we provided."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ptwVEIqTPgcr",
      "metadata": {
        "id": "ptwVEIqTPgcr"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "JAnB8zBcPlN1",
      "metadata": {
        "id": "JAnB8zBcPlN1"
      },
      "outputs": [],
      "source": [
        "#Please keep only necessary information in this cell.\n",
        "\n",
        "#----------------------Please keep all following constants unchanged.----------------------------------------\n",
        "NUM_ROWS_VALIDATION = 1031 # Number of rows in validation set\n",
        "NUM_ROWS_TEST = 1053 # Number of rows in test set\n",
        "\n",
        "#----------------------Please modify the following constants to fit your actual value.-----------------------\n",
        "STUDENT_ID = '11445473'  # Replace with your actual 8-digits student ID\n",
        "TRAINING_SET = './data/CW2_training_dataset.csv' # Replace with the actual path to your training dataset csv file\n",
        "VALIDATION_SET = './data/CW2_validation_dataset.csv'  # Replace with the actual path to your validation dataset csv file\n",
        "VALIDATION_SET_OUTPUT = f'./data/{STUDENT_ID}_CW2_task2_validation_results.csv'  # Replace with the actual path to your validation prediction csv file\n",
        "TEST_SET_INPUT = './data/CW2_test_dataset.csv'  # Replace with the actual path to your test prediction csv file\n",
        "\n",
        "#----------------------Your constants------------------------------------------------\n",
        "# By adding more constants here, you can help improve the clarity and maintainability of your code and make the reviewing easier for TAs.\n",
        "MODEL_NAME = \"roberta-base\"\n",
        "NUM_LABELS = 8\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 16\n",
        "LR = 2e-5\n",
        "EPOCHS = 3\n",
        "MAX_SYNOPSIS_LENGTH = 5000\n",
        "HIDDEN_DIM = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bd0de31",
      "metadata": {
        "id": "9bd0de31"
      },
      "source": [
        "## Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "4ce6c494",
      "metadata": {
        "id": "4ce6c494"
      },
      "outputs": [],
      "source": [
        "# Install required packages for the coursework\n",
        "# Uncomment and run the following lines if needed\n",
        "\n",
        "# !pip install pandas scikit-learn --quiet\n",
        "# !pip install transformers datasets torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "434f6a76",
      "metadata": {
        "id": "434f6a76"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "cd4d0b96",
      "metadata": {
        "id": "cd4d0b96"
      },
      "outputs": [],
      "source": [
        "#Please keep all imports of your code cells in this cell\n",
        "\n",
        "#---------------------Required imports----------------------\n",
        "import pandas as pd\n",
        "import re\n",
        "import sys\n",
        "import os.path\n",
        "import csv\n",
        "from sklearn.metrics import f1_score\n",
        "#----------------------Your imports-------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5087e9a2",
      "metadata": {
        "id": "5087e9a2"
      },
      "source": [
        "## Start of your code cells\n",
        "\n",
        "- The code cells provided below are demo code format for TAs to quickly locate your implementation.\n",
        "\n",
        "- You have full right to freely add/delete/edit the titles and codes in the following cells.\n",
        "\n",
        "- Please follow this genre order: \"comedy, cult, flashback, historical, revenge, romantic, scifi, violence\"."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0542a6ae",
      "metadata": {},
      "source": [
        "### Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "c0e1f5a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta_model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Freeze it - don't retrain\n",
        "for param in roberta_model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf9a6526",
      "metadata": {
        "id": "bf9a6526"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "8a4e80b1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 4.7943,  2.9572,  2.5724, 36.3141,  3.2423,  2.5760, 33.4300,  1.3506],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "#this makes sure to use the gpu if available otherwise the cpu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Your code cells here\n",
        "df = pd.read_csv(TRAINING_SET)\n",
        "\n",
        "GENRE_COLS = [\n",
        "    \"comedy\", \"cult\", \"flashback\", \"historical\",\n",
        "    \"revenge\", \"romantic\", \"scifi\", \"violence\"\n",
        "]\n",
        "\n",
        "# extract Y from training df\n",
        "Y_train = df[GENRE_COLS].values   # shape (7127, 8)\n",
        "\n",
        "# Count positives and negatives per label\n",
        "pos_counts = Y_train.sum(axis=0)\n",
        "neg_counts = (Y_train.shape[0] - pos_counts)\n",
        "\n",
        "# Compute pos_weight = neg/pos\n",
        "pos_weight = torch.tensor(neg_counts / pos_counts, dtype=torch.float32).to(device)\n",
        "\n",
        "print(pos_weight)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f88adca5",
      "metadata": {
        "id": "f88adca5"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "440536bc",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "tokenizer.padding_side = \"right\"\n",
        "tokenizer.truncation_side = \"right\"\n",
        "model = RobertaModel.from_pretrained('roberta-base')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "a84fa785",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MovieDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.genre_cols = [\n",
        "            \"comedy\", \"cult\", \"flashback\", \"historical\",\n",
        "            \"revenge\", \"romantic\", \"scifi\", \"violence\"\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        text = f\"{row.title} [SEP] {row.plot_synopsis}\"\n",
        "\n",
        "        # Tokenize directly with max_length=512\n",
        "        enc = self.tokenizer(\n",
        "            text,\n",
        "            max_length=512,         # roberta-base max tokens\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        labels = torch.tensor(row[self.genre_cols].values.astype(float), dtype=torch.float)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": labels\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b83dc91",
      "metadata": {
        "id": "6b83dc91"
      },
      "source": [
        "### Model and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "1c47ba16",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import RobertaModel\n",
        "\n",
        "class RobertaBiLSTMClassifier(nn.Module):\n",
        "    def __init__(self, hidden_dim=256, num_labels=8, roberta_model_name=\"roberta-base\", pos_weight=None):\n",
        "        super().__init__()\n",
        "\n",
        "        # Pretrained RoBERTa\n",
        "        self.roberta = RobertaModel.from_pretrained(roberta_model_name)\n",
        "\n",
        "        for param in self.roberta.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # BiLSTM on top of RoBERTa embeddings\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=768,       # RoBERTa hidden size\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=1,\n",
        "            bidirectional=True,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "        self.fc = nn.Linear(2 * hidden_dim, num_labels)\n",
        "        \n",
        "        # Store pos_weight as a buffer (automatically moves to device with model)\n",
        "        if pos_weight is not None:\n",
        "            self.register_buffer('pos_weight', pos_weight)\n",
        "        else:\n",
        "            self.pos_weight = None\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        # RoBERTa embeddings\n",
        "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        embeddings = outputs.last_hidden_state  # [batch, seq_len, 768]\n",
        "\n",
        "        lengths = attention_mask.sum(dim=1).cpu()\n",
        "\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(\n",
        "            embeddings, \n",
        "            lengths,\n",
        "            batch_first=True,\n",
        "            enforce_sorted=False\n",
        "        )\n",
        "\n",
        "        packed_out, (h_n, c_n) = self.lstm(packed)\n",
        "        h_forward = h_n[0]    # forward direction\n",
        "        h_backward = h_n[1]   # backward direction\n",
        "        h_final = torch.cat([h_forward, h_backward], dim=1)\n",
        "\n",
        "        # Classifier\n",
        "        logits = self.fc(h_final)\n",
        "        \n",
        "        if labels is not None:\n",
        "            loss_fn = nn.BCEWithLogitsLoss(pos_weight=self.pos_weight)\n",
        "            loss = loss_fn(logits, labels)\n",
        "            return loss, logits\n",
        "        \n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "12cb655e",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = MovieDataset(df, tokenizer)\n",
        "\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size= BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "60e65011",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "  Batch 0: Probs - min=0.447, max=0.612, mean=0.516\n",
            "  Batch 50: Probs - min=0.446, max=0.616, mean=0.511\n",
            "  Batch 100: Probs - min=0.442, max=0.610, mean=0.513\n",
            "  Batch 150: Probs - min=0.446, max=0.605, mean=0.510\n",
            "  Batch 200: Probs - min=0.455, max=0.586, mean=0.509\n",
            "  Batch 250: Probs - min=0.453, max=0.587, mean=0.507\n",
            "  Batch 300: Probs - min=0.450, max=0.560, mean=0.507\n",
            "  Batch 350: Probs - min=0.447, max=0.576, mean=0.507\n",
            "  Batch 400: Probs - min=0.469, max=0.567, mean=0.508\n",
            "Epoch 1/10, Loss = 1.0928\n",
            "  Batch 0: Probs - min=0.455, max=0.562, mean=0.506\n",
            "  Batch 50: Probs - min=0.466, max=0.548, mean=0.507\n",
            "  Batch 100: Probs - min=0.473, max=0.549, mean=0.507\n",
            "  Batch 150: Probs - min=0.466, max=0.545, mean=0.508\n",
            "  Batch 200: Probs - min=0.477, max=0.539, mean=0.506\n",
            "  Batch 250: Probs - min=0.467, max=0.542, mean=0.506\n",
            "  Batch 300: Probs - min=0.462, max=0.554, mean=0.504\n",
            "  Batch 350: Probs - min=0.471, max=0.552, mean=0.504\n",
            "  Batch 400: Probs - min=0.460, max=0.543, mean=0.504\n",
            "Epoch 2/10, Loss = 1.0856\n",
            "  Batch 0: Probs - min=0.469, max=0.553, mean=0.504\n",
            "  Batch 50: Probs - min=0.452, max=0.545, mean=0.501\n",
            "  Batch 100: Probs - min=0.467, max=0.548, mean=0.503\n",
            "  Batch 150: Probs - min=0.456, max=0.571, mean=0.502\n",
            "  Batch 200: Probs - min=0.470, max=0.540, mean=0.502\n",
            "  Batch 250: Probs - min=0.467, max=0.559, mean=0.505\n",
            "  Batch 300: Probs - min=0.442, max=0.542, mean=0.501\n",
            "  Batch 350: Probs - min=0.461, max=0.545, mean=0.500\n",
            "  Batch 400: Probs - min=0.446, max=0.550, mean=0.499\n",
            "Epoch 3/10, Loss = 1.0805\n",
            "  Batch 0: Probs - min=0.463, max=0.531, mean=0.499\n",
            "  Batch 50: Probs - min=0.437, max=0.541, mean=0.498\n",
            "  Batch 100: Probs - min=0.442, max=0.541, mean=0.496\n",
            "  Batch 150: Probs - min=0.428, max=0.542, mean=0.495\n",
            "  Batch 200: Probs - min=0.427, max=0.556, mean=0.496\n",
            "  Batch 250: Probs - min=0.418, max=0.543, mean=0.496\n",
            "  Batch 300: Probs - min=0.445, max=0.555, mean=0.496\n",
            "  Batch 350: Probs - min=0.433, max=0.541, mean=0.497\n",
            "  Batch 400: Probs - min=0.421, max=0.558, mean=0.497\n",
            "Epoch 4/10, Loss = 1.0749\n",
            "  Batch 0: Probs - min=0.426, max=0.551, mean=0.498\n",
            "  Batch 50: Probs - min=0.447, max=0.546, mean=0.498\n",
            "  Batch 100: Probs - min=0.438, max=0.574, mean=0.498\n",
            "  Batch 150: Probs - min=0.426, max=0.558, mean=0.496\n",
            "  Batch 200: Probs - min=0.427, max=0.549, mean=0.496\n",
            "  Batch 250: Probs - min=0.416, max=0.551, mean=0.495\n",
            "  Batch 300: Probs - min=0.441, max=0.534, mean=0.497\n",
            "  Batch 350: Probs - min=0.441, max=0.546, mean=0.498\n",
            "  Batch 400: Probs - min=0.394, max=0.557, mean=0.494\n",
            "Epoch 5/10, Loss = 1.0683\n",
            "  Batch 0: Probs - min=0.433, max=0.557, mean=0.498\n",
            "  Batch 50: Probs - min=0.383, max=0.586, mean=0.493\n",
            "  Batch 100: Probs - min=0.413, max=0.594, mean=0.500\n",
            "  Batch 150: Probs - min=0.419, max=0.580, mean=0.497\n",
            "  Batch 200: Probs - min=0.418, max=0.561, mean=0.497\n",
            "  Batch 250: Probs - min=0.411, max=0.587, mean=0.500\n",
            "  Batch 300: Probs - min=0.444, max=0.543, mean=0.496\n",
            "  Batch 350: Probs - min=0.411, max=0.568, mean=0.496\n",
            "  Batch 400: Probs - min=0.395, max=0.635, mean=0.496\n",
            "Epoch 6/10, Loss = 1.0582\n",
            "  Batch 0: Probs - min=0.396, max=0.634, mean=0.495\n",
            "  Batch 50: Probs - min=0.388, max=0.591, mean=0.494\n",
            "  Batch 100: Probs - min=0.359, max=0.569, mean=0.489\n",
            "  Batch 150: Probs - min=0.401, max=0.658, mean=0.496\n",
            "  Batch 200: Probs - min=0.376, max=0.595, mean=0.490\n",
            "  Batch 250: Probs - min=0.343, max=0.576, mean=0.486\n",
            "  Batch 300: Probs - min=0.382, max=0.598, mean=0.490\n",
            "  Batch 350: Probs - min=0.409, max=0.649, mean=0.498\n",
            "  Batch 400: Probs - min=0.368, max=0.675, mean=0.492\n",
            "Epoch 7/10, Loss = 1.0453\n",
            "  Batch 0: Probs - min=0.358, max=0.626, mean=0.492\n",
            "  Batch 50: Probs - min=0.324, max=0.570, mean=0.484\n",
            "  Batch 100: Probs - min=0.335, max=0.594, mean=0.484\n",
            "  Batch 150: Probs - min=0.331, max=0.624, mean=0.491\n",
            "  Batch 200: Probs - min=0.323, max=0.590, mean=0.486\n",
            "  Batch 250: Probs - min=0.298, max=0.652, mean=0.488\n",
            "  Batch 300: Probs - min=0.352, max=0.694, mean=0.489\n",
            "  Batch 350: Probs - min=0.356, max=0.667, mean=0.494\n",
            "  Batch 400: Probs - min=0.299, max=0.675, mean=0.490\n",
            "Epoch 8/10, Loss = 1.0261\n",
            "  Batch 0: Probs - min=0.323, max=0.675, mean=0.490\n",
            "  Batch 50: Probs - min=0.270, max=0.664, mean=0.487\n",
            "  Batch 100: Probs - min=0.304, max=0.618, mean=0.483\n",
            "  Batch 150: Probs - min=0.290, max=0.644, mean=0.482\n",
            "  Batch 200: Probs - min=0.273, max=0.623, mean=0.483\n",
            "  Batch 250: Probs - min=0.281, max=0.770, mean=0.482\n",
            "  Batch 300: Probs - min=0.274, max=0.685, mean=0.479\n",
            "  Batch 350: Probs - min=0.252, max=0.640, mean=0.483\n",
            "  Batch 400: Probs - min=0.235, max=0.744, mean=0.485\n",
            "Epoch 9/10, Loss = 1.0021\n",
            "  Batch 0: Probs - min=0.266, max=0.647, mean=0.479\n",
            "  Batch 50: Probs - min=0.253, max=0.710, mean=0.474\n",
            "  Batch 100: Probs - min=0.259, max=0.685, mean=0.477\n",
            "  Batch 150: Probs - min=0.243, max=0.813, mean=0.481\n",
            "  Batch 200: Probs - min=0.239, max=0.652, mean=0.479\n",
            "  Batch 250: Probs - min=0.215, max=0.728, mean=0.471\n",
            "  Batch 300: Probs - min=0.239, max=0.817, mean=0.472\n",
            "  Batch 350: Probs - min=0.188, max=0.734, mean=0.477\n",
            "  Batch 400: Probs - min=0.266, max=0.827, mean=0.482\n",
            "Epoch 10/10, Loss = 0.9821\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "model = RobertaBiLSTMClassifier(hidden_dim=HIDDEN_DIM, pos_weight=pos_weight).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Load test set\n",
        "validation_df_raw = pd.read_csv(VALIDATION_SET)\n",
        "\n",
        "X_validation = MovieDataset(validation_df_raw, tokenizer)\n",
        "validation_loader = DataLoader(X_validation, batch_size= BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(device)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(loader):\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss, logits = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 50 == 0:  # Every 50 batches\n",
        "            with torch.no_grad():\n",
        "                probs = torch.sigmoid(logits)\n",
        "                print(f\"  Batch {i}: Probs - min={probs.min():.3f}, max={probs.max():.3f}, mean={probs.mean():.3f}\")\n",
        "\n",
        "        total_loss += loss.item() * input_ids.size(0)\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss = {avg_loss:.4f}\")\n",
        "\n",
        "    # Validate after each epoch\n",
        "    model.eval()\n",
        "    val_probs = []\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            probs = torch.sigmoid(logits)\n",
        "            val_probs.append(probs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "40b8c59d",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"bilstm_genre_model_task2.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "280a5a0b",
      "metadata": {},
      "source": [
        "### Finding the best thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "46f103ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load test set\n",
        "validation_df_raw = pd.read_csv(VALIDATION_SET)\n",
        "\n",
        "X_validation = MovieDataset(validation_df_raw, tokenizer)\n",
        "validation_loader = DataLoader(X_validation, batch_size= BATCH_SIZE, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "all_probs = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in validation_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        loss, logits = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        probs = torch.sigmoid(logits).cpu()\n",
        "\n",
        "        all_probs.append(probs)\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "probs_val = torch.cat(all_probs, dim=0).numpy()\n",
        "y_val = torch.cat(all_labels, dim=0).cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "id": "bd5b8f6a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.4797608  0.38017586 0.56683415 0.4137713  0.48122752 0.6662515\n",
            " 0.1957885  0.38954678]\n",
            "[0. 0. 1. 0. 1. 0. 0. 1.]\n"
          ]
        }
      ],
      "source": [
        "print(probs_val[10])\n",
        "print(y_val[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "id": "b0d2527e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BEST THRESHOLDS PER GENRE:\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n"
          ]
        }
      ],
      "source": [
        "def find_best_thresholds(probs, y_true):\n",
        "    thresholds = np.linspace(0, 1, 101)  # 0.00 â†’ 1.00\n",
        "    best_thresholds = []\n",
        "\n",
        "    for col in range(probs.shape[1]):   # for each genre\n",
        "        best_f1 = 0\n",
        "        best_thr = 0.5\n",
        "\n",
        "        for thr in thresholds:\n",
        "            preds = (probs[:, col] >= thr).astype(int)\n",
        "            f1 = f1_score(y_true[:, col], preds, zero_division=0)\n",
        "\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_thr = thr\n",
        "\n",
        "        best_thresholds.append(best_thr)\n",
        "\n",
        "    return np.array(best_thresholds)\n",
        "\n",
        "best_thresholds = find_best_thresholds(probs_val, y_val)\n",
        "print(\"BEST THRESHOLDS PER GENRE:\")\n",
        "print(best_thresholds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "22fb2f03",
      "metadata": {},
      "outputs": [],
      "source": [
        "#best_thresholds = np.array([0.46, 0.38, 0.34, 0.79, 0.42, 0.55, 0.93, 0.34])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5563b2d4",
      "metadata": {
        "id": "5563b2d4"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "19306f79",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "word_to_vec = {}\n",
        "\n",
        "model.eval()\n",
        "\n",
        "def predict_dataframe(df, model, tokenizer, batch_size=BATCH_SIZE, device=\"cuda\"):\n",
        "    dataset = MovieDataset(df, tokenizer)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    all_preds = []\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            probs = torch.sigmoid(logits)\n",
        "\n",
        "            # If you have per-label thresholds\n",
        "            print(best_thresholds)\n",
        "            thresholds_tensor = torch.tensor(best_thresholds, device=probs.device, dtype=probs.dtype)\n",
        "            preds = (probs >= thresholds_tensor).int()\n",
        "\n",
        "            all_preds.append(preds.cpu())\n",
        "\n",
        "    all_preds = torch.cat(all_preds, dim=0).numpy()\n",
        "    return all_preds  # shape: (len(df), 8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03c72dda",
      "metadata": {
        "id": "03c72dda"
      },
      "source": [
        "## End of your code cells"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0a88f81",
      "metadata": {},
      "source": [
        "### Evaluation scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "fa286438",
      "metadata": {
        "cellView": "form",
        "id": "fa286438"
      },
      "outputs": [],
      "source": [
        "def read_data(submission_file_path, gold_standard_file_path):\n",
        "    \"\"\"\n",
        "    Read submission and gold standard files.\n",
        "    Extract student ID from filename.\n",
        "    \"\"\"\n",
        "    # Try to find student ID from the filename (looks for 8 digit numbers)\n",
        "    id_regex = r'\\d{8}'\n",
        "\n",
        "    user_id = re.findall(id_regex, submission_file_path)\n",
        "    print(\"Found your ID: \", user_id)\n",
        "    if user_id:\n",
        "        user_id = user_id[0]\n",
        "    else:\n",
        "        user_id = 'Unknown'\n",
        "\n",
        "    # Load submission CSV\n",
        "    print(f\"\\nLoading submission file: {submission_file_path}\")\n",
        "    submission_df = pd.read_csv(submission_file_path, sep=',', header=None,\n",
        "                                quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
        "\n",
        "    # Load gold standard CSV\n",
        "    print(f\"Loading gold standard file: {gold_standard_file_path}\")\n",
        "    gold_standard_df = pd.read_csv(gold_standard_file_path, header=None)\n",
        "\n",
        "    # Remove columns 1 and 2 (keep only ID and labels)\n",
        "    gold_standard_df = gold_standard_df.drop([1, 2], axis=1)\n",
        "    # Skip header row\n",
        "    gold_standard_df = gold_standard_df.iloc[1:]\n",
        "\n",
        "    return submission_df, gold_standard_df, user_id\n",
        "\n",
        "\n",
        "def match_and_prepare_data(submission_df, gold_standard_df, user_id):\n",
        "    \"\"\"\n",
        "    Match submission rows with gold standard rows by ID.\n",
        "    Prepare data for evaluation.\n",
        "    \"\"\"\n",
        "    gold_standard_labels = []\n",
        "    submission_labels = []\n",
        "    missed_rows = []\n",
        "    submission_df_copy = submission_df.copy()\n",
        "\n",
        "    print(f\"\\nMatching submission with gold standard...\")\n",
        "    print(f\"Gold standard rows: {len(gold_standard_df)}\")\n",
        "    print(f\"Submission rows: {len(submission_df_copy)}\")\n",
        "\n",
        "    # Match each gold standard row with submission\n",
        "    for index, row in gold_standard_df.iterrows():\n",
        "        row = row.reset_index(drop=True)\n",
        "        row_found = False\n",
        "        row_id = row[0]\n",
        "\n",
        "        # Extract gold standard labels\n",
        "        row_labels = [int(row[i]) for i in range(1, len(row))]\n",
        "        gold_standard_labels.append(row_labels)\n",
        "\n",
        "        # Find corresponding submission row\n",
        "        for sub_index, submission_row in submission_df_copy.iterrows():\n",
        "            if submission_row[0].strip() == row_id.strip():\n",
        "                try:\n",
        "                    # Extract submission labels\n",
        "                    submission_row_labels = [int(submission_row[i]) for i in range(1, len(submission_row))]\n",
        "                except:\n",
        "                    # Handle malformed labels (take first character if multi-digit)\n",
        "                    submission_row_labels = [int(str(submission_row[i])[0]) for i in range(1, len(submission_row))]\n",
        "\n",
        "                submission_labels.append(submission_row_labels)\n",
        "                row_found = True\n",
        "                submission_df_copy.drop(sub_index, inplace=True)\n",
        "                break\n",
        "\n",
        "        if not row_found:\n",
        "            # If row is missing, add inverse labels (worst possible prediction)\n",
        "            missed_rows.append(row_id)\n",
        "            submission_labels.append([0 if label == 1 else 1 for label in row_labels])\n",
        "\n",
        "    return gold_standard_labels, submission_labels, missed_rows\n",
        "\n",
        "\n",
        "def evaluate_submission(gold_standard_labels, submission_labels):\n",
        "    \"\"\"\n",
        "    Calculate weighted F1 score.\n",
        "    \"\"\"\n",
        "    print(f\"\\nCalculating weighted F1 score...\")\n",
        "\n",
        "    # Calculate weighted F1 score (accounts for class imbalance)\n",
        "    f1_weighted = f1_score(gold_standard_labels, submission_labels, average='weighted')\n",
        "\n",
        "    return f1_weighted\n",
        "\n",
        "\n",
        "def print_results(user_id, f1_weighted, missed_rows):\n",
        "    \"\"\"\n",
        "    Print evaluation results to screen.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"YOUR SUBMISSION EVALUATION REPORT\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Alert if ID not found in filename\n",
        "    if user_id == 'Unknown':\n",
        "        print('WARNING: ID not found in filename!')\n",
        "        print('   Please ensure your filename contains your 8-digit student ID.')\n",
        "        print()\n",
        "\n",
        "    print(f\"Your ID: {user_id}\")\n",
        "    print()\n",
        "\n",
        "    # Display F1 score with visual indicator\n",
        "    print(\"EVALUATION RESULTS:\")\n",
        "    print(f\"   Weighted F1 Score: {f1_weighted:.4f}\")\n",
        "    print()\n",
        "\n",
        "    # Report missing rows\n",
        "    if missed_rows:\n",
        "        print(f\"MISSING DATA ({len(missed_rows)} rows not found):\")\n",
        "        print(\"-\" * 70)\n",
        "        for i, row in enumerate(missed_rows[:10], 1):  # Show first 10\n",
        "            print(f\"    {i}. Row ID: {row}\")\n",
        "        if len(missed_rows) > 10:\n",
        "            print(f\"    ... and {len(missed_rows) - 10} more missing rows\")\n",
        "        print()\n",
        "        print(\"TIP: Make sure your submission includes all required rows.\")\n",
        "        print(\"        Missing rows are penalized with worst possible predictions.\")\n",
        "    else:\n",
        "        print(\"DATA COMPLETENESS: All expected rows found in your submission!\")\n",
        "\n",
        "    print()\n",
        "    print(\"=\"*70)\n",
        "    print()\n",
        "\n",
        "\n",
        "def evaluate(submission_path, gold_standard_path):\n",
        "    \"\"\"\n",
        "    Main function to run the submission evaluation script.\n",
        "    \"\"\"\n",
        "\n",
        "    submission_file = submission_path\n",
        "    gold_standard_file = gold_standard_path\n",
        "\n",
        "    # Check if files exist\n",
        "    if not os.path.exists(submission_file):\n",
        "        print(f\"Error: Your submission file '{submission_file}' not found!\")\n",
        "        print(\"Make sure the file path is correct and the file exists.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    if not os.path.exists(gold_standard_file):\n",
        "        print(f\"Error: Gold standard file '{gold_standard_file}' not found!\")\n",
        "        print(\"Make sure you have the correct gold standard file.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    try:\n",
        "        # Step 1: Read data\n",
        "        submission_df, gold_standard_df, user_id = read_data(submission_file, gold_standard_file)\n",
        "\n",
        "        # Step 2: Match and prepare data\n",
        "        gold_standard_labels, submission_labels, missed_rows = match_and_prepare_data(\n",
        "            submission_df, gold_standard_df, user_id\n",
        "        )\n",
        "\n",
        "        # Step 3: Evaluate\n",
        "        f1_weighted = evaluate_submission(gold_standard_labels, submission_labels)\n",
        "\n",
        "        # Step 4: Print results\n",
        "        print_results(user_id, f1_weighted, missed_rows)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during evaluation: {str(e)}\")\n",
        "        print(\"Please check that your files are in the correct CSV format.\")\n",
        "        print(\"Each row should contain: ID, label1, label2, label3, ...\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        sys.exit(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "733177b7",
      "metadata": {},
      "source": [
        "### Evaluate the model on the validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "aca9a479",
      "metadata": {
        "id": "aca9a479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found your ID:  ['11445473']\n",
            "\n",
            "Loading submission file: ./data/11445473_CW2_task2_validation_results.csv\n",
            "Loading gold standard file: ./data/CW2_validation_dataset.csv\n",
            "\n",
            "Matching submission with gold standard...\n",
            "Gold standard rows: 1031\n",
            "Submission rows: 1031\n",
            "\n",
            "Calculating weighted F1 score...\n",
            "\n",
            "======================================================================\n",
            "YOUR SUBMISSION EVALUATION REPORT\n",
            "======================================================================\n",
            "Your ID: 11445473\n",
            "\n",
            "EVALUATION RESULTS:\n",
            "   Weighted F1 Score: 0.5006\n",
            "\n",
            "DATA COMPLETENESS: All expected rows found in your submission!\n",
            "\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Please run the evaluation scripts cell above before running the mark_and_record\n",
        "\n",
        "# Please make sure that output format is like following (no header row, no tilte and plot columns):\n",
        "# 94834c61-0e30-4799-9998-6f74f6sbb204\t0\t1\t0\t0\t1\t0\t0\t0\n",
        "# 559sdd28-b6a2-4662-ab55-a6678as26a56\t0\t0\t0\t0\t0\t0\t1\t0\n",
        "# b71y3317-04cd-42f5-a380-d21dfasdbd36\t0\t0\t0\t0\t1\t0\t0\t0\n",
        "\n",
        "evaluation_results = evaluate(VALIDATION_SET_OUTPUT, VALIDATION_SET)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9106288d",
      "metadata": {
        "id": "9106288d"
      },
      "source": [
        "### Save predictions to formatted file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "ea616ed6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.52\n",
            "0.41000000000000003\n",
            "0.43\n",
            "0.68\n",
            "0.46\n",
            "0.51\n",
            "0.73\n",
            "0.37\n"
          ]
        }
      ],
      "source": [
        "for i in best_thresholds:\n",
        "    print(i)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "id": "fe5d8fb7",
      "metadata": {
        "id": "fe5d8fb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n",
            "[0.52 0.41 0.43 0.68 0.46 0.51 0.73 0.37]\n"
          ]
        }
      ],
      "source": [
        "# Now please modify the code to format your output csv file.\n",
        "\n",
        "# Please make sure that output format is like following (no header row, no tilte and plot columns):\n",
        "# 94834c61-0e30-4799-9998-6f74f6sbb204\t0\t1\t0\t0\t1\t0\t0\t0\n",
        "# 559sdd28-b6a2-4662-ab55-a6678as26a56\t0\t0\t0\t0\t0\t0\t1\t0\n",
        "# b71y3317-04cd-42f5-a380-d21dfasdbd36\t0\t0\t0\t0\t1\t0\t0\t0\n",
        "\n",
        "test_df = pd.read_csv(VALIDATION_SET)\n",
        "test_preds = predict_dataframe(test_df, model, tokenizer)\n",
        "\n",
        "output_df = pd.DataFrame(test_preds, columns=GENRE_COLS)\n",
        "output_df.insert(0, 'ID', test_df['ID'])\n",
        "\n",
        "# For example, if you have a DataFrame named 'output_df', you can save it\n",
        "#assert isinstance(output_df, pd.DataFrame)\n",
        "#assert len(output_df) == NUM_ROWS_TEST, \"Output length is not aligned with the testdata.csv.\"\n",
        "#assert len(output_df.columns) == 9, \"Please make sure to follow the format above and keep only IDs and 8 columns of prediction.\"\n",
        "output_df.to_csv(f'./data/{STUDENT_ID}_CW2_task2_validation_results.csv', index=False, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26125e2f",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
